**My version of nanoGPT trained on tiny Shakespeare. This is a follow along on Andrej Karpathy lecture on YouTube :)**

Initial loss of the transformer is ~4.2, after training and hyperparameter tuning, the final training loss was ~0.91

Output of the first 10000 tokens can be found in the output file, in the dataset folder
